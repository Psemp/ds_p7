{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import shap\n",
    "import gc\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.mlflow_functions import train_and_log\n",
    "from models.scorer import home_credit_scoring_fn, home_credit_scorer, hc_threshold_score\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n",
    "\n",
    "client = mlflow.MlflowClient(tracking_uri=os.path.abspath(\"../mlruns/\"))\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mlflow.create_experiment(name=\"home_credit_model\")\n",
    "except mlflow.MlflowException:\n",
    "    mlflow.set_experiment(experiment_name=\"home_credit_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle(filepath_or_buffer=\"../data/df_hc_nm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.rename(columns={\"TARGET\": \"Loan_granted\"}, inplace=True)\n",
    "\n",
    "target_col = \"Loan_granted\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"Loan_granted\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 : Modelisation and experimentation\n",
    "\n",
    "- Threshold optimization : The first xgboost run will be used to adjust the threshold of the scorer\n",
    "- Models : Ensemble methods, handle missing values and don't require scaling\n",
    "    - xGBoost\n",
    "    - CatBoost\n",
    "    - LightGBM\n",
    "- Optimization : Best method will be determined via benchmark\n",
    "    - GridSearchCV\n",
    "    - Hyperopt\n",
    "- Logging via MlFlow :\n",
    "    - Metrics\n",
    "    - Custom metric tuning\n",
    "    - AUROC, confusion matrix\n",
    "    - Global feature importance\n",
    "    - Model\n",
    "    - Method of undersampling\n",
    "    - Version (handling of nans.)\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training, validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    df_model.drop(columns=target_col),\n",
    "    df_model[target_col],\n",
    "    test_size=0.3,\n",
    "    random_state=123\n",
    "    )\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=0.25,\n",
    "    random_state=123\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 xGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", np.arange(200, 800, 25, dtype=int)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.arange(3, 9, dtype=int)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", -7, -3),\n",
    "    \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 6, 0.1),\n",
    "    \"reg_alpha\": hp.loguniform(\"reg_alpha\", -6, -3),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", -6, -3),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 0.9),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.3, 0.9),\n",
    "    \"nthread\": -1\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        min_child_weight=params[\"min_child_weight\"],\n",
    "        reg_alpha=params[\"reg_alpha\"],\n",
    "        reg_lambda=params[\"reg_lambda\"],\n",
    "        subsample=params[\"subsample\"],\n",
    "        colsample_bytree=params[\"colsample_bytree\"],\n",
    "        nthread=params[\"nthread\"]\n",
    "    )\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=home_credit_scorer)\n",
    "    loss = -np.mean(scores)\n",
    "    return {\"loss\": loss, \"status\": \"ok\"}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "time_start_hopt = time.perf_counter()\n",
    "best = fmin(objective, space=xgb_param_space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "time_end_hopt = time.perf_counter()\n",
    "\n",
    "print(f\"Hyperopt search time: {time_end_hopt - time_start_hopt} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = space_eval(xgb_param_space, best)\n",
    "gc.collect()\n",
    "print(best_params_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name=\"home_credit_model\")\n",
    "\n",
    "best_params_xgb_log = {\n",
    "    \"colsample_bytree\": 0.778655523535136,\n",
    "    \"learning_rate\": 0.0054998702766629335,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 2.0,\n",
    "    \"n_estimators\": 700,\n",
    "    \"reg_alpha\": 0.037071627790320846,\n",
    "    \"reg_lambda\": 0.006294264780463717,\n",
    "    \"subsample\": 0.8644766597785274\n",
    "    }\n",
    "\n",
    "xgb_metrics, xgb_clf = train_and_log(\n",
    "    estimator=XGBClassifier,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    dataset_version=\"nans_kept_shap_reduced\",\n",
    "    imb_method=\"near_miss_one\",\n",
    "    na_thresh=0,\n",
    "    params=best_params_xgb_log,\n",
    "    model_name=\"xgboost_best_hyperopt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There might be overfitting, we will try and adjust it\n",
    "\n",
    "y_proba = xgb_clf.predict_proba(X_val)\n",
    "\n",
    "optimal_threshold = hc_threshold_score(y_val, y_proba)\n",
    "\n",
    "y_pred = (y_proba[:, 1] >= optimal_threshold).astype(int)\n",
    "\n",
    "score = home_credit_scoring_fn(y_val, y_pred)\n",
    "print(\"Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking the high AUC with classification report\n",
    "\n",
    "y_val_proba = xgb_clf.predict_proba(X_val)\n",
    "y_val_pred = xgb_clf.predict(X_val)\n",
    "\n",
    "report = classification_report(y_val, y_val_pred)\n",
    "val_score = home_credit_scoring_fn(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation score: {val_score}\")\n",
    "print(report)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations :\n",
    "With an AUC of .881, it might be considered that the model is overfitting - or the fact that the competition is quite old in a machine learning POV might explain why xGboost is having such high performances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 : Catboost :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_param_space = {\n",
    "    \"iterations\": hp.choice(\"iterations\", np.arange(200, 800, 25, dtype=int)),\n",
    "    \"depth\": hp.choice(\"depth\", np.arange(3, 9, dtype=int)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", -7, -3),\n",
    "    \"l2_leaf_reg\": hp.loguniform(\"l2_leaf_reg\", -6, -3),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 0.9),\n",
    "    \"colsample_bylevel\": hp.uniform(\"colsample_bylevel\", 0.3, 0.9),\n",
    "    \"thread_count\": -1\n",
    "    }\n",
    "\n",
    "\n",
    "def objective_cb(params):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=params[\"iterations\"],\n",
    "        depth=params[\"depth\"],\n",
    "        subsample=params[\"subsample\"],\n",
    "        colsample_bylevel=params[\"colsample_bylevel\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        l2_leaf_reg=params[\"l2_leaf_reg\"],\n",
    "        verbose=False,\n",
    "    )\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=home_credit_scorer)\n",
    "    loss = -np.mean(scores)\n",
    "    return {\"loss\": loss, \"status\": \"ok\"}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "time_start_hopt = time.perf_counter()\n",
    "best_cb = fmin(objective_cb, space=catboost_param_space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "time_end_hopt = time.perf_counter()\n",
    "\n",
    "print(f\"Hyperopt search time: {time_end_hopt - time_start_hopt} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_cb = space_eval(catboost_param_space, best_cb)\n",
    "print(best_params_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name=\"home_credit_model\")\n",
    "\n",
    "best_params_cb_log = {\n",
    "    \"colsample_bylevel\": 0.8492535750204921,\n",
    "    \"depth\": 7,\n",
    "    \"iterations\": 700,\n",
    "    \"l2_leaf_reg\": 0.011953394749318379,\n",
    "    \"learning_rate\": 0.018551685647746795,\n",
    "    \"subsample\": 0.8297130817489142,\n",
    "    \"verbose\": False\n",
    "    }\n",
    "\n",
    "cb_metrics, cb_clf = train_and_log(\n",
    "    estimator=CatBoostClassifier,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    dataset_version=\"nans_kept_shap_reduced\",\n",
    "    imb_method=\"near_miss_one\",\n",
    "    na_thresh=0,\n",
    "    params=best_params_cb_log,\n",
    "    model_name=\"catboost_cvalidated\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking the high AUC with classification report\n",
    "\n",
    "y_val_proba_cb = cb_clf.predict_proba(X_val)\n",
    "y_val_pred_cb = cb_clf.predict(X_val)\n",
    "\n",
    "report_cb = classification_report(y_val, y_val_pred_cb)\n",
    "val_score_cb = home_credit_scoring_fn(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation score: {val_score_cb}\")\n",
    "print(report_cb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The problem of our generic function doesnt account for catboost specific scoring args, will be addressed at the end of the nb by defining again the functions imported for mlflow_function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7413ceb39ad46ea0813b284866778c289877dcdb7cc0e15aac0f5b04eb145bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
