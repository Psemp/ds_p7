{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import pickle\n",
    "import evidently\n",
    "import urllib\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# EVIDENTLY :\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.metric_preset import ClassificationPreset\n",
    "# /EVIDENTLY\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n",
    "\n",
    "client = mlflow.MlflowClient(tracking_uri=os.path.abspath(\"../mlruns/\"))\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook focuses on the evaluation of the potential data drift of the retained models\n",
    "- Retained models are xgboost and catboost (Keras DNN is less accurate and requires more data preprocessing, see previous nb.)\n",
    "- Evidently will be used to simulate the addition of data over time\n",
    "- This will be done under the assumption that `applications_train` is known data and `applications_test` is unseen data.\n",
    "- The aim is to detect eventual drift and propose solutions to counter it, either by retraining the model or other options that Evidently proposes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 : Recovering the models from MLFlow and restoring the splits\n",
    "- Both catboost and xgboost have been trained, crossvalidated and assessed on a hold out set. These models have been logged through mlflow along their hyperparameters. We can avoid recomputing the models by loading the serialized files from MLFlow.\n",
    "- The data used for training will be restored as it was done in the previous notebook (random seed of `123` and `train/test/validation` split)\n",
    "- The variable order is important to evidently, so we will also load the training columns, also saved in MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST CV infos :\n",
    "xgb_run_id = \"f62231946a8f412d87a1198a731827b8\"\n",
    "xgb_run = mlflow.get_run(run_id=xgb_run_id)\n",
    "\n",
    "xgb_artifact_uri = xgb_run.info.artifact_uri\n",
    "\n",
    "xgb_mlflow_model = f\"runs:/{xgb_run_id}/xGboost-model\"\n",
    "\n",
    "xgb_classifier = mlflow.xgboost.load_model(model_uri=xgb_mlflow_model)\n",
    "\n",
    "# columns train : \n",
    "columns_file = \"columns_train/columns_train.pkl\"\n",
    "columns_path = os.path.join(xgb_artifact_uri, columns_file)\n",
    "columns_path = urllib.parse.urlparse(columns_path).path\n",
    "\n",
    "with open(columns_path, \"rb\") as col_pkl:\n",
    "    columns_train = pickle.load(col_pkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost CV :\n",
    "\n",
    "cb_run_id = \"c21201ee795547eda136f395bf3ec8a6\"\n",
    "cb_run = mlflow.get_run(run_id=cb_run_id)\n",
    "\n",
    "cb_artifact_uri = cb_run.info.artifact_uri\n",
    "\n",
    "cb_mlflow_model = f\"runs:/{cb_run_id}/catboost-model\"\n",
    "\n",
    "cb_classifier = mlflow.catboost.load_model(model_uri=cb_mlflow_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the training data and restoring the initial split :\n",
    "df_train = pd.read_pickle(filepath_or_buffer=\"../data/df_hc_nm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={\"TARGET\": \"Payment_difficulties\"}, inplace=True)\n",
    "\n",
    "target_col = \"Payment_difficulties\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training, validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    df_train.drop(columns=target_col),\n",
    "    df_train[target_col],\n",
    "    test_size=0.3,\n",
    "    random_state=123\n",
    "    )\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=0.25,\n",
    "    random_state=123\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown data loading :\n",
    "\n",
    "df_unknown = pd.read_pickle(filepath_or_buffer=\"../data/home_credit_data_test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of the columns used by estimators : \n",
    "\n",
    "df_unknown = df_unknown[columns_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 : General pupose functions :\n",
    "- `generate_report` : takes a classifier, known and unknown data to generate a drift report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(clf, known_data: pd.DataFrame, unknown_data: pd.DataFrame, target_col: str):\n",
    "    \"\"\"\n",
    "    Generate reports using Evidently library.\n",
    "\n",
    "    Args:\n",
    "    - clf : Fitted classifier object (xgboost or catboost).\n",
    "    - known_data : Dataframe containing the known data (labelled).\n",
    "    - unknown_data : Dataframe containing the unknown data (no label col.).\n",
    "    - target_col : Name of the target column in the dataframes.\n",
    "\n",
    "    Returns:\n",
    "    - drift_report : Data drift report object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get predictions for the known data\n",
    "    known_data[\"prediction\"] = clf.predict(known_data.drop(target_col, axis=1))\n",
    "\n",
    "    # Get predictions for the unknown data\n",
    "    unknown_data[\"prediction\"] = clf.predict(unknown_data)  # No target -> no need to drop\n",
    "\n",
    "    known_data = known_data.drop(columns=target_col)\n",
    "\n",
    "    # Generate data drift report\n",
    "    drift_report = Report(metrics=[DataDriftPreset()])\n",
    "    drift_report.run(reference_data=known_data, current_data=unknown_data)\n",
    "\n",
    "    return drift_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 : Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known = pd.concat([X_train, y_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling because it takes ages : \n",
    "\n",
    "df_known_sample = df_known.sample(n=10_000, replace=False, random_state=123)\n",
    "df_unknown_sample = df_unknown.sample(n=10_000, replace=False, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5060\n",
       "0    4940\n",
       "Name: Payment_difficulties, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_known_sample[\"Payment_difficulties\"].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 : xGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_drift = generate_report(\n",
    "    clf=xgb_classifier,\n",
    "    known_data=df_known_sample,\n",
    "    unknown_data=df_unknown_sample,\n",
    "    target_col=\"Payment_difficulties\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_drift.save_html(filename=\"../data/xgb_drift.html\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 : Catboost :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_drift = generate_report(\n",
    "    clf=cb_classifier,\n",
    "    known_data=df_known_sample,\n",
    "    unknown_data=df_unknown_sample,\n",
    "    target_col=\"Payment_difficulties\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_drift.save_html(filename=\"../data/catboost_drift.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
