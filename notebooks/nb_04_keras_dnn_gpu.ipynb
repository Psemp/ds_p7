{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import shap\n",
    "import gc\n",
    "import subprocess\n",
    "import tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from models.scorer import home_credit_scoring_fn, home_credit_scorer, home_credit_fn_keras\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mlflow.create_experiment(name=\"home_credit_model\")\n",
    "except mlflow.MlflowException:\n",
    "    mlflow.set_experiment(experiment_name=\"home_credit_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle(filepath_or_buffer=\"../data/df_hc_nm_imputed.pkl\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to redefine binary cols as variables that use 0, 1 or -1 (sentinel) :\n",
    "\n",
    "def detect_binary_cols_with_sentinel(dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Detects binary columns in a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "    - df: pandas dataframe.\n",
    "\n",
    "    Returns:\n",
    "    - list of binary column names.\n",
    "    \"\"\"\n",
    "\n",
    "    binary_cols = []\n",
    "\n",
    "    for col in dataframe.columns:\n",
    "        unique_vals = dataframe[col].dropna().unique()\n",
    "        if len(unique_vals) == 2 and set(unique_vals) == {0, 1}:\n",
    "            binary_cols.append(col)\n",
    "\n",
    "    return binary_cols\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the binary cols (0 , 1, -1 (sentinel)) : not to scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = detect_binary_cols_with_sentinel(dataframe=df_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_to_scale = [col for col in df_model.columns if col not in binary_cols]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the numeric columns for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_model[numeric_to_scale] = scaler.fit_transform(df_model[numeric_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_model.drop(columns=[\"TARGET\"]),\n",
    "    df_model[\"TARGET\"],\n",
    "    test_size=0.3,\n",
    "    random_state=123,\n",
    "    stratify=df_model[\"TARGET\"]\n",
    "    )\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=123,\n",
    "    stratify=y_train\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN : \n",
    "\n",
    "- input of size feature len\n",
    "- 512 dense\n",
    "- dropout 30%\n",
    "- 256 dense\n",
    "- dropout 20%\n",
    "- Sigmoid for binary clf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model :\n",
    "model = tensorflow.keras.Sequential()\n",
    "model.add(tensorflow.keras.layers.Dense(512, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
    "model.add(tensorflow.keras.layers.Dropout(0.3))\n",
    "model.add(tensorflow.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tensorflow.keras.layers.Dropout(0.2))\n",
    "model.add(tensorflow.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tensorflow.keras.metrics.Recall()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f6b751e199dcbabb2ce7588a17371d0fea6f86ffe7dee2feeaaa0a8e52803ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
